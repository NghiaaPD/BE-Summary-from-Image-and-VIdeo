{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f28f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torchvision.transforms as transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70af7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trích xuất frames từ video\n",
    "def extract_frames(video_path, frame_interval=10):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    count_frames = 0\n",
    "\n",
    "    if not os.path.exists('frames'):\n",
    "        os.makedirs('frames')\n",
    "    \n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if count_frames % frame_interval == 0:\n",
    "            # cv2.imshow('Output: ', frame)\n",
    "            cv2.imwrite(f'frames/frame_{count_frames}.jpg', frame)\n",
    "        count_frames += 1\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1de36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mô tả từng khung hình bằng model Florence-2\n",
    "# def describe_frames(frames, florence_processor, florence_model):\n",
    "#     task_prompt = \"<MORE_DETAILED_CAPTION>\"\n",
    "#     frame_descriptions = []\n",
    "#     for frame in frames:\n",
    "#         image = Image.open(os.path.join('frames', frame))\n",
    "\n",
    "#         # Generate content   \n",
    "#         if image.mode != \"RGB\":\n",
    "#             image = image.convert(\"RGB\")\n",
    "\n",
    "#         inputs = florence_processor(text=task_prompt, images=image, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "#         generated_ids = florence_model.generate(\n",
    "#             input_ids=inputs[\"input_ids\"],\n",
    "#             pixel_values=inputs[\"pixel_values\"],\n",
    "#             max_new_tokens=1024,\n",
    "#             num_beams=3\n",
    "#         )\n",
    "#         generated_text = florence_processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "#         parsed_answer = florence_processor.post_process_generation(generated_text, task=task_prompt, image_size=(image.width, image.height))\n",
    "#         frame_descriptions.append(parsed_answer)\n",
    "    \n",
    "#     return frame_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1610995",
   "metadata": {},
   "source": [
    "Test multi processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f925765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniforge3\\envs\\dpl_be\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Khởi tạo Florence-2 model và processor một lần\n",
    "florence_model = AutoModelForCausalLM.from_pretrained('microsoft/Florence-2-base-ft', trust_remote_code=True).eval().cuda()\n",
    "florence_processor = AutoProcessor.from_pretrained('microsoft/Florence-2-base-ft', trust_remote_code=True)\n",
    "\n",
    "# Worker function to process frames (sử dụng model đã khởi tạo)\n",
    "def describe_frame_worker(frame, task_prompt=\"<MORE_DETAILED_CAPTION>\"):\n",
    "    # Load and process image\n",
    "    image = Image.open(os.path.join('frames', frame))\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    \n",
    "    inputs = florence_processor(text=task_prompt, images=image, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "    generated_ids = florence_model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        max_new_tokens=1024,\n",
    "        num_beams=3\n",
    "    )\n",
    "    generated_text = florence_processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    parsed_answer = florence_processor.post_process_generation(generated_text, task=task_prompt, image_size=(image.width, image.height))\n",
    "    \n",
    "    return parsed_answer\n",
    "\n",
    "# Hàm thực hiện đa luồng xử lý nhiều frame\n",
    "def describe_frames_threaded(frames):\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:  # Tùy chỉnh số lượng luồng\n",
    "        future_to_frame = {executor.submit(describe_frame_worker, frame): frame for frame in frames}\n",
    "        frame_descriptions = []\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_frame):\n",
    "            try:\n",
    "                frame_descriptions.append(future.result())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing frame: {e}\")\n",
    "\n",
    "    return frame_descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee525e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tổng hợp thông tin bằng BART \n",
    "def summarize_descriptions(descriptions, bart_model, bart_tokenizer):\n",
    "    # Ghép nối các mô tả thành một đoạn văn bản\n",
    "    combined_text = \" \".join([desc[\"<MORE_DETAILED_CAPTION>\"] for desc in descriptions])\n",
    "\n",
    "    # Tokenizer và tạo input cho model BART\n",
    "    inputs = bart_tokenizer.encode(\"summarize: \" + combined_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    \n",
    "    # Dự đoán tóm tắt\n",
    "    summary_ids = bart_model.generate(inputs, max_length=200, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b15171a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE\n",
    "def summarize_video_content(video_path, frame_rate=1):\n",
    "    global florence_processor, florence_model, bart_model, bart_tokenizer\n",
    "\n",
    "    # Xoá folder frame hiện tại\n",
    "    if os.path.exists('frames'):\n",
    "        for frame in os.listdir('frames'):\n",
    "            os.remove(os.path.join('frames', frame))\n",
    "    \n",
    "    extract_frames(video_path, frame_rate)\n",
    "    frames = os.listdir('frames')\n",
    "    # descriptions = describe_frames(frames, florence_processor, florence_model) \n",
    "    descriptions = describe_frames_threaded(frames)\n",
    "    summary = summarize_descriptions(descriptions, bart_model, bart_tokenizer)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3988caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# florence_model = AutoModelForCausalLM.from_pretrained('microsoft/Florence-2-base-ft', trust_remote_code=True).eval().cuda()\n",
    "# florence_processor = AutoProcessor.from_pretrained('microsoft/Florence-2-base-ft', trust_remote_code=True)\n",
    "bart_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "bart_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f481db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r'videos\\\\video_3.mp4'\n",
    "summary = summarize_video_content(video_path, frame_rate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddf7def8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are people standing on the grass. There are colorful balloons floating in the air. There is a white ball on the ground in front of the balloons. A bunch of kites are flying in the sky.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d03a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpl_be",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
