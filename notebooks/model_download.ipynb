{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f28f721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniforge3\\envs\\dpl_be\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torchvision.transforms as transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70af7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tr√≠ch xu·∫•t frames t·ª´ video\n",
    "def extract_frames(video_path, frame_interval=10):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    count_frames = 0\n",
    "\n",
    "    if not os.path.exists('frames'):\n",
    "        os.makedirs('frames')\n",
    "    \n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if count_frames % frame_interval == 0:\n",
    "            # cv2.imshow('Output: ', frame)\n",
    "            cv2.imwrite(f'frames/frame_{count_frames}.jpg', frame)\n",
    "        count_frames += 1\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1de36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√¥ t·∫£ t·ª´ng khung h√¨nh b·∫±ng model Florence-2\n",
    "def describe_frames(frames, florence_processor, florence_model):\n",
    "    task_prompt = \"<MORE_DETAILED_CAPTION>\"\n",
    "    frame_descriptions = []\n",
    "    for frame in frames:\n",
    "        image = Image.open(os.path.join('frames', frame))\n",
    "\n",
    "        # Generate content   \n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "\n",
    "        inputs = florence_processor(text=task_prompt, images=image, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "        generated_ids = florence_model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            pixel_values=inputs[\"pixel_values\"],\n",
    "            max_new_tokens=1024,\n",
    "            num_beams=3\n",
    "        )\n",
    "        generated_text = florence_processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "        parsed_answer = florence_processor.post_process_generation(generated_text, task=task_prompt, image_size=(image.width, image.height))\n",
    "        frame_descriptions.append(parsed_answer)\n",
    "    \n",
    "    return frame_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1610995",
   "metadata": {},
   "source": [
    "Test multi processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a55cf101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "# H√†m m√¥ t·∫£ m·ªôt khung h√¨nh, t·∫°o l·∫°i m√¥ h√¨nh trong m·ªói ti·∫øn tr√¨nh\n",
    "def describe_frame_single(frame, task_prompt):\n",
    "    # T·∫°o l·∫°i processor v√† model trong m·ªói ti·∫øn tr√¨nh\n",
    "    florence_model = AutoModelForCausalLM.from_pretrained('microsoft/Florence-2-base-ft', trust_remote_code=True).eval().cuda()\n",
    "    florence_processor = AutoProcessor.from_pretrained('microsoft/Florence-2-base-ft', trust_remote_code=True)\n",
    "\n",
    "    image = Image.open(os.path.join('frames', frame))\n",
    "\n",
    "    # Generate content   \n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "    inputs = florence_processor(text=task_prompt, images=image, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "    generated_ids = florence_model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        max_new_tokens=1024,\n",
    "        num_beams=3\n",
    "    )\n",
    "    generated_text = florence_processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    parsed_answer = florence_processor.post_process_generation(generated_text, task=task_prompt, image_size=(image.width, image.height))\n",
    "    \n",
    "    return parsed_answer\n",
    "\n",
    "# H√†m ƒëa ti·∫øn tr√¨nh s·ª≠ d·ª•ng Pool\n",
    "def describe_frames_multiprocessing_pool(frames, num_processes=4):\n",
    "    task_prompt = \"<MORE_DETAILED_CAPTION>\"\n",
    "    \n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        # S·ª≠ d·ª•ng Pool ƒë·ªÉ x·ª≠ l√Ω c√°c frame song song\n",
    "        results = pool.starmap(describe_frame_single, [(frame, task_prompt) for frame in frames])\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee525e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·ªïng h·ª£p th√¥ng tin b·∫±ng BART \n",
    "def summarize_descriptions(descriptions, bart_model, bart_tokenizer):\n",
    "    # Gh√©p n·ªëi c√°c m√¥ t·∫£ th√†nh m·ªôt ƒëo·∫°n vƒÉn b·∫£n\n",
    "    combined_text = \" \".join([desc[\"<MORE_DETAILED_CAPTION>\"] for desc in descriptions])\n",
    "\n",
    "    # Tokenizer v√† t·∫°o input cho model BART\n",
    "    inputs = bart_tokenizer.encode(\"summarize: \" + combined_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    \n",
    "    # D·ª± ƒëo√°n t√≥m t·∫Øt\n",
    "    summary_ids = bart_model.generate(inputs, max_length=200, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15171a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE\n",
    "def summarize_video_content(video_path, frame_rate=1):\n",
    "    global florence_processor, florence_model, bart_model, bart_tokenizer\n",
    "\n",
    "    # Xo√° folder frame hi·ªán t·∫°i\n",
    "    if os.path.exists('frames'):\n",
    "        for frame in os.listdir('frames'):\n",
    "            os.remove(os.path.join('frames', frame))\n",
    "    \n",
    "    extract_frames(video_path, frame_rate)\n",
    "    frames = os.listdir('frames')\n",
    "    descriptions = describe_frames(frames, florence_processor, florence_model) \n",
    "    # descriptions = describe_frames_multiprocessing_pool(frames, num_processes=4)\n",
    "    summary = summarize_descriptions(descriptions, bart_model, bart_tokenizer)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3988caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "c:\\ProgramData\\miniforge3\\envs\\dpl_be\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "florence_model = AutoModelForCausalLM.from_pretrained('microsoft/Florence-2-base-ft', trust_remote_code=True).eval().cuda()\n",
    "florence_processor = AutoProcessor.from_pretrained('microsoft/Florence-2-base-ft', trust_remote_code=True)\n",
    "bart_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "bart_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f481db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r'videos\\\\video_2.mp4'\n",
    "summary = summarize_video_content(video_path, frame_rate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf7def8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A green parrot with a red beak is sitting on a branch of a tree. There are green leaves on the branches of the tree. The parrot has a blue body and a red head. The background of the image is blurred.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d03a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpl_be",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
